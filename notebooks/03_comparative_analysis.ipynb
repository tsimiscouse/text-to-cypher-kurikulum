{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis: Baseline vs Agentic\n",
    "\n",
    "Notebook ini membandingkan hasil agentic loop dengan baseline (linear pipeline).\n",
    "\n",
    "## Perbandingan:\n",
    "- Pass@1 Rate improvement\n",
    "- KG Validity improvement\n",
    "- LLMetric improvement\n",
    "- Impact of self-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [14, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Baseline Results (from kg-axel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline results from Axel's research\n",
    "# These values should be updated with actual baseline results from kg-axel\n",
    "\n",
    "baseline_results = {\n",
    "    \"Zero-Shot_Full\": {\n",
    "        \"pass_at_1_rate\": 0.0,  # Update with actual value\n",
    "        \"kg_valid_rate\": 0.0,   # Update with actual value\n",
    "        \"llmetric\": 0.0,        # Update with actual value\n",
    "    },\n",
    "    \"Zero-Shot_Nodes+Paths\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "    \"Zero-Shot_Paths\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "    \"Few-Shot_Full\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "    \"Few-Shot_Nodes+Paths\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "    \"Few-Shot_Paths\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "    \"CoT_Full\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "    \"CoT_Nodes+Paths\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "    \"CoT_Paths\": {\n",
    "        \"pass_at_1_rate\": 0.0,\n",
    "        \"kg_valid_rate\": 0.0,\n",
    "        \"llmetric\": 0.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Baseline results loaded (update with actual values from kg-axel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline from CSV if available\n",
    "# kg_axel_results_path = Path(\"/Users/tsimiscouse/Docs/Sarjana/Skripsi/kg-axel/results/...\")\n",
    "\n",
    "# Alternative: Load from kg-axel evaluation results\n",
    "# if kg_axel_results_path.exists():\n",
    "#     baseline_df = pd.read_csv(kg_axel_results_path)\n",
    "#     print(baseline_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Agentic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load agentic results\n",
    "results_dir = project_root / \"results\"\n",
    "summary_path = results_dir / \"experiment_summary.json\"\n",
    "\n",
    "if summary_path.exists():\n",
    "    with open(summary_path, \"r\") as f:\n",
    "        agentic_summary = json.load(f)\n",
    "    print(f\"Loaded agentic results from: {agentic_summary['timestamp']}\")\n",
    "else:\n",
    "    print(\"No agentic results found. Please run inference first.\")\n",
    "    agentic_summary = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs agentic\n",
    "if agentic_summary:\n",
    "    comparison_rows = []\n",
    "    \n",
    "    for config_name, agentic_config in agentic_summary['configurations'].items():\n",
    "        baseline = baseline_results.get(config_name, {})\n",
    "        \n",
    "        baseline_pass = baseline.get('pass_at_1_rate', 0)\n",
    "        baseline_kg = baseline.get('kg_valid_rate', 0)\n",
    "        baseline_llm = baseline.get('llmetric', 0)\n",
    "        \n",
    "        agentic_pass = agentic_config['pass_at_1_rate']\n",
    "        agentic_kg = agentic_config['kg_valid_rate']\n",
    "        agentic_llm = agentic_config['llmetric']\n",
    "        \n",
    "        agentic_metrics = agentic_config.get('agentic_metrics', {})\n",
    "        \n",
    "        comparison_rows.append({\n",
    "            \"Configuration\": config_name,\n",
    "            \"Baseline Pass@1 (%)\": baseline_pass,\n",
    "            \"Agentic Pass@1 (%)\": round(agentic_pass, 2),\n",
    "            \"Pass@1 Δ (pp)\": round(agentic_pass - baseline_pass, 2),\n",
    "            \"Baseline KG Valid (%)\": baseline_kg,\n",
    "            \"Agentic KG Valid (%)\": round(agentic_kg, 2),\n",
    "            \"KG Valid Δ (pp)\": round(agentic_kg - baseline_kg, 2),\n",
    "            \"Baseline LLMetric\": baseline_llm,\n",
    "            \"Agentic LLMetric\": round(agentic_llm, 2),\n",
    "            \"LLMetric Δ\": round(agentic_llm - baseline_llm, 2),\n",
    "            \"Recovery Rate (%)\": round(agentic_metrics.get('recovery_rate', 0) * 100, 2),\n",
    "            \"Avg Iterations\": round(agentic_metrics.get('avg_iterations', 0), 2),\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_rows)\n",
    "    df_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass@1 Improvement\n",
    "if agentic_summary and baseline_results:\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    x = np.arange(len(df_comparison))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, df_comparison['Baseline Pass@1 (%)'], width, \n",
    "                   label='Baseline (Linear)', color='gray', alpha=0.7)\n",
    "    bars2 = ax.bar(x + width/2, df_comparison['Agentic Pass@1 (%)'], width,\n",
    "                   label='Agentic (Loop)', color='steelblue')\n",
    "    \n",
    "    ax.set_xlabel('Configuration')\n",
    "    ax.set_ylabel('Pass@1 Rate (%)')\n",
    "    ax.set_title('Pass@1 Rate: Baseline vs Agentic')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_comparison['Configuration'], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'baseline_vs_agentic_pass1.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvement Delta\n",
    "if agentic_summary and baseline_results:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # Pass@1 Delta\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_comparison['Pass@1 Δ (pp)']]\n",
    "    axes[0].bar(df_comparison['Configuration'], df_comparison['Pass@1 Δ (pp)'], color=colors)\n",
    "    axes[0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    axes[0].set_xlabel('Configuration')\n",
    "    axes[0].set_ylabel('Improvement (pp)')\n",
    "    axes[0].set_title('Pass@1 Improvement')\n",
    "    axes[0].set_xticklabels(df_comparison['Configuration'], rotation=45, ha='right')\n",
    "    \n",
    "    # KG Valid Delta\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_comparison['KG Valid Δ (pp)']]\n",
    "    axes[1].bar(df_comparison['Configuration'], df_comparison['KG Valid Δ (pp)'], color=colors)\n",
    "    axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    axes[1].set_xlabel('Configuration')\n",
    "    axes[1].set_ylabel('Improvement (pp)')\n",
    "    axes[1].set_title('KG Validity Improvement')\n",
    "    axes[1].set_xticklabels(df_comparison['Configuration'], rotation=45, ha='right')\n",
    "    \n",
    "    # LLMetric Delta\n",
    "    colors = ['green' if x > 0 else 'red' for x in df_comparison['LLMetric Δ']]\n",
    "    axes[2].bar(df_comparison['Configuration'], df_comparison['LLMetric Δ'], color=colors)\n",
    "    axes[2].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    axes[2].set_xlabel('Configuration')\n",
    "    axes[2].set_ylabel('Improvement')\n",
    "    axes[2].set_title('LLMetric Improvement')\n",
    "    axes[2].set_xticklabels(df_comparison['Configuration'], rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'improvement_delta.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Self-Correction Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze where self-correction helped\n",
    "if agentic_summary:\n",
    "    print(\"\\n=== Self-Correction Impact Analysis ===\")\n",
    "    print(\"\\nQuestions that were initially wrong but corrected after refinement:\")\n",
    "    \n",
    "    for config_name, config in agentic_summary['configurations'].items():\n",
    "        agentic_metrics = config.get('agentic_metrics', {})\n",
    "        \n",
    "        first_attempt_rate = agentic_metrics.get('first_attempt_success_rate', 0) * 100\n",
    "        final_success_rate = config['kg_valid_rate']\n",
    "        recovery_rate = agentic_metrics.get('recovery_rate', 0) * 100\n",
    "        \n",
    "        improvement_from_correction = final_success_rate - first_attempt_rate\n",
    "        \n",
    "        print(f\"\\n{config_name}:\")\n",
    "        print(f\"  First Attempt Success: {first_attempt_rate:.1f}%\")\n",
    "        print(f\"  Final Success Rate: {final_success_rate:.1f}%\")\n",
    "        print(f\"  Improvement from Correction: +{improvement_from_correction:.1f}pp\")\n",
    "        print(f\"  Recovery Rate: {recovery_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterations to Success Distribution\n",
    "if agentic_summary:\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (config_name, config) in enumerate(agentic_summary['configurations'].items()):\n",
    "        agentic_metrics = config.get('agentic_metrics', {})\n",
    "        iter_to_success = agentic_metrics.get('iterations_to_success', {})\n",
    "        \n",
    "        if iter_to_success:\n",
    "            iterations = list(iter_to_success.keys())\n",
    "            counts = list(iter_to_success.values())\n",
    "            \n",
    "            axes[i].bar(iterations, counts, color='steelblue')\n",
    "            axes[i].set_xlabel('Iterations Needed')\n",
    "            axes[i].set_ylabel('Count')\n",
    "            axes[i].set_title(config_name)\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, 'No data', ha='center', va='center')\n",
    "            axes[i].set_title(config_name)\n",
    "    \n",
    "    plt.suptitle('Iterations to Success Distribution', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_dir / 'iterations_distribution.png', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "if agentic_summary:\n",
    "    print(\"\\n=== Overall Experiment Statistics ===\")\n",
    "    \n",
    "    all_pass1 = [c['pass_at_1_rate'] for c in agentic_summary['configurations'].values()]\n",
    "    all_kg = [c['kg_valid_rate'] for c in agentic_summary['configurations'].values()]\n",
    "    all_llm = [c['llmetric'] for c in agentic_summary['configurations'].values()]\n",
    "    \n",
    "    print(f\"\\nPass@1 Rate:\")\n",
    "    print(f\"  Mean: {np.mean(all_pass1):.2f}%\")\n",
    "    print(f\"  Std: {np.std(all_pass1):.2f}%\")\n",
    "    print(f\"  Best: {max(all_pass1):.2f}%\")\n",
    "    print(f\"  Worst: {min(all_pass1):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nKG Valid Rate:\")\n",
    "    print(f\"  Mean: {np.mean(all_kg):.2f}%\")\n",
    "    print(f\"  Std: {np.std(all_kg):.2f}%\")\n",
    "    print(f\"  Best: {max(all_kg):.2f}%\")\n",
    "    print(f\"  Worst: {min(all_kg):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nLLMetric:\")\n",
    "    print(f\"  Mean: {np.mean(all_llm):.2f}\")\n",
    "    print(f\"  Std: {np.std(all_llm):.2f}\")\n",
    "    print(f\"  Best: {max(all_llm):.2f}\")\n",
    "    print(f\"  Worst: {min(all_llm):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best configuration\n",
    "if agentic_summary:\n",
    "    best_pass1_config = max(agentic_summary['configurations'].items(), \n",
    "                           key=lambda x: x[1]['pass_at_1_rate'])\n",
    "    best_kg_config = max(agentic_summary['configurations'].items(), \n",
    "                        key=lambda x: x[1]['kg_valid_rate'])\n",
    "    best_llm_config = max(agentic_summary['configurations'].items(), \n",
    "                         key=lambda x: x[1]['llmetric'])\n",
    "    \n",
    "    print(\"\\n=== Best Configurations ===\")\n",
    "    print(f\"\\nBest Pass@1: {best_pass1_config[0]} ({best_pass1_config[1]['pass_at_1_rate']:.2f}%)\")\n",
    "    print(f\"Best KG Valid: {best_kg_config[0]} ({best_kg_config[1]['kg_valid_rate']:.2f}%)\")\n",
    "    print(f\"Best LLMetric: {best_llm_config[0]} ({best_llm_config[1]['llmetric']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comparison to CSV\n",
    "if agentic_summary:\n",
    "    comparative_dir = results_dir / \"comparative\"\n",
    "    comparative_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    export_path = comparative_dir / \"baseline_vs_agentic.csv\"\n",
    "    df_comparison.to_csv(export_path, index=False)\n",
    "    print(f\"Exported comparison to: {export_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
